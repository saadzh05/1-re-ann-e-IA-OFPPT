import streamlit as st
import os
import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision import transforms
import time
import tempfile
import zipfile
import io
import base64
from pathlib import Path

st.set_page_config(
    page_title="ğŸš¶â€â™‚ï¸ DÃ©tecteur de PiÃ©tons IA",
    page_icon="ğŸš¶â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)


class PedestrianDetectorStreamlit:
    def __init__(self, model_path='best_model.pth', confidence_threshold=0.5):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.confidence_threshold = confidence_threshold
        self.model = self._load_model(model_path)

    def _load_model(self, model_path):
        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)
        num_classes = 2
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

        if os.path.exists(model_path):
            model.load_state_dict(torch.load(model_path, map_location=self.device))

        model.to(self.device)
        model.eval()
        return model

    def _preprocess_image(self, image_array):
        height, width = image_array.shape[:2]
        max_size = 1024

        if max(height, width) > max_size:
            scale = max_size / max(height, width)
            new_width = int(width * scale)
            new_height = int(height * scale)
            image_array = cv2.resize(image_array, (new_width, new_height))

        image_tensor = torch.from_numpy(image_array / 255.0).permute(2, 0, 1).float()
        image_tensor = image_tensor.to(self.device).unsqueeze(0)

        return image_array, image_tensor

    def detect_pedestrians(self, image_array):
        start_time = time.time()

        try:
            image_rgb, image_tensor = self._preprocess_image(image_array)

            with torch.no_grad():
                predictions = self.model(image_tensor)[0]

            boxes = predictions['boxes'].cpu().numpy()
            scores = predictions['scores'].cpu().numpy()
            labels = predictions['labels'].cpu().numpy()

            confident_detections = scores >= self.confidence_threshold
            final_boxes = boxes[confident_detections]
            final_scores = scores[confident_detections]
            final_labels = labels[confident_detections]

            annotated_image = self._draw_detections(
                image_rgb.copy(), final_boxes, final_scores, final_labels
            )

            processing_time = time.time() - start_time

            detection_stats = {
                'total_detections': len(final_boxes),
                'processing_time': processing_time,
                'average_confidence': np.mean(final_scores) if len(final_scores) > 0 else 0,
                'detections': [
                    {
                        'box': box.tolist(),
                        'confidence': float(score),
                        'label': 'Pietons'
                    }
                    for box, score in zip(final_boxes, final_scores)
                ]
            }

            return annotated_image, detection_stats

        except Exception as e:
            st.error(f"Erreur pendant la dÃ©tection: {e}")
            return None, {'error': str(e), 'total_detections': 0}

    def _draw_detections(self, image, boxes, scores, labels):
        for box, score, label in zip(boxes, scores, labels):
            x1, y1, x2, y2 = box.astype(int)

            if score > 0.8:
                color = (0, 255, 0)
            elif score > 0.6:
                color = (255, 255, 0)
            else:
                color = (255, 165, 0)

            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

            text = f'Pieton {score:.2f}'
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]

            cv2.rectangle(image, (x1, y1 - text_size[1] - 10),
                          (x1 + text_size[0], y1), color, -1)

            cv2.putText(image, text, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        return image


@st.cache_resource
def load_detector(model_path, confidence):
    return PedestrianDetectorStreamlit(model_path, confidence)


def create_download_link(img_array, filename):
    img_pil = Image.fromarray(img_array)
    buf = io.BytesIO()
    img_pil.save(buf, format='PNG')
    buf.seek(0)

    b64 = base64.b64encode(buf.read()).decode()
    href = f'<a href="data:image/png;base64,{b64}" download="{filename}">ğŸ“¥ TÃ©lÃ©charger l\'image annotÃ©e</a>'
    return href


def main():
    st.title("ğŸš¶â€â™‚ï¸ DÃ©tecteur de PiÃ©tons par Intelligence Artificielle")
    st.markdown("---")

    st.sidebar.header("âš™ï¸ ParamÃ¨tres")

    model_path = st.sidebar.text_input("Chemin du modÃ¨le", value="best_model.pth")
    confidence_threshold = st.sidebar.slider(
        "Seuil de confiance",
        min_value=0.1,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="Plus le seuil est Ã©levÃ©, plus les dÃ©tections sont sÃ»res mais moins nombreuses"
    )

    st.sidebar.markdown("### ğŸ’» Informations SystÃ¨me")
    device = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
    st.sidebar.info(f"**Device:** {device}")

    if not os.path.exists(model_path):
        st.sidebar.warning("âš ï¸ ModÃ¨le personnalisÃ© non trouvÃ©. Utilisation du modÃ¨le prÃ©-entraÃ®nÃ©.")
    else:
        st.sidebar.success("âœ… ModÃ¨le personnalisÃ© chargÃ©")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¸ Image unique", "ğŸ“ Lot d'images", "ğŸ“¹ Temps rÃ©el", "ğŸ“Š Statistiques"])

    with tab1:
        st.header("ğŸ“¸ DÃ©tection sur image unique")

        uploaded_file = st.file_uploader(
            "Choisissez une image",
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="Formats supportÃ©s: JPG, JPEG, PNG, BMP"
        )

        if uploaded_file is not None:
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Image originale")
                image = Image.open(uploaded_file)
                image_array = np.array(image)
                st.image(image, caption="Image uploadÃ©e", use_container_width=True)
                st.info(f"**Dimensions:** {image.size[0]} x {image.size[1]} pixels")

            with col2:
                st.subheader("RÃ©sultat de la dÃ©tection")

                if st.button("ğŸ” DÃ©tecter les piÃ©tons", type="primary"):
                    detector = load_detector(model_path, confidence_threshold)

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text("Initialisation...")
                    progress_bar.progress(25)

                    status_text.text("Analyse de l'image...")
                    progress_bar.progress(50)

                    annotated_image, stats = detector.detect_pedestrians(image_array)

                    progress_bar.progress(75)
                    status_text.text("Finalisation...")

                    if annotated_image is not None:
                        progress_bar.progress(100)
                        status_text.text("TerminÃ©!")

                        st.image(annotated_image, caption="DÃ©tections", use_container_width=True)

                        col_stat1, col_stat2, col_stat3 = st.columns(3)

                        with col_stat1:
                            st.metric("ğŸ¯ PiÃ©tons dÃ©tectÃ©s", stats['total_detections'])

                        with col_stat2:
                            st.metric("â±ï¸ Temps (s)", f"{stats['processing_time']:.2f}")

                        with col_stat3:
                            if stats['total_detections'] > 0:
                                st.metric("ğŸ“Š Confiance moy.", f"{stats['average_confidence']:.2f}")
                            else:
                                st.metric("ğŸ“Š Confiance moy.", "N/A")

                        if stats['total_detections'] > 0:
                            st.subheader("ğŸ“‹ DÃ©tails des dÃ©tections")
                            for i, detection in enumerate(stats['detections'], 1):
                                with st.expander(f"PiÃ©ton {i} - Confiance: {detection['confidence']:.2f}"):
                                    box = detection['box']
                                    st.write(
                                        f"**Position:** x1={box[0]:.0f}, y1={box[1]:.0f}, x2={box[2]:.0f}, y2={box[3]:.0f}")
                                    st.write(f"**Largeur:** {box[2] - box[0]:.0f} pixels")
                                    st.write(f"**Hauteur:** {box[3] - box[1]:.0f} pixels")

                        st.markdown("---")
                        download_link = create_download_link(annotated_image, "detection_result.png")
                        st.markdown(download_link, unsafe_allow_html=True)

                        progress_bar.empty()
                        status_text.empty()

    with tab2:
        st.header("ğŸ“ Traitement par lot")
        st.info("ğŸ’¡ Uploadez plusieurs images pour un traitement automatique en lot")

        uploaded_files = st.file_uploader(
            "Choisissez plusieurs images",
            type=['jpg', 'jpeg', 'png', 'bmp'],
            accept_multiple_files=True,
            help="SÃ©lectionnez plusieurs fichiers pour le traitement en lot"
        )

        if uploaded_files:
            st.write(f"ğŸ“Š {len(uploaded_files)} images sÃ©lectionnÃ©es")

            if st.button("ğŸš€ Traiter toutes les images", type="primary"):
                detector = load_detector(model_path, confidence_threshold)

                results = []
                total_detections = 0
                total_time = 0

                progress_bar = st.progress(0)
                status_text = st.empty()

                for i, uploaded_file in enumerate(uploaded_files):
                    status_text.text(f"Traitement de {uploaded_file.name}...")
                    progress_bar.progress((i + 1) / len(uploaded_files))

                    image = Image.open(uploaded_file)
                    image_array = np.array(image)

                    annotated_image, stats = detector.detect_pedestrians(image_array)

                    if annotated_image is not None:
                        results.append({
                            'name': uploaded_file.name,
                            'image': annotated_image,
                            'stats': stats
                        })
                        total_detections += stats['total_detections']
                        total_time += stats['processing_time']

                status_text.text("Traitement terminÃ©!")

                st.subheader("ğŸ“Š RÃ©sumÃ© du traitement")
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("ğŸ“ Images traitÃ©es", len(results))
                with col2:
                    st.metric("ğŸ¯ Total dÃ©tections", total_detections)
                with col3:
                    st.metric("â±ï¸ Temps total", f"{total_time:.1f}s")
                with col4:
                    st.metric("ğŸ“ˆ Moyenne/image", f"{total_detections / len(results):.1f}")

                st.subheader("ğŸ–¼ï¸ RÃ©sultats dÃ©taillÃ©s")

                for result in results:
                    with st.expander(f"{result['name']} - {result['stats']['total_detections']} piÃ©tons"):
                        col_img, col_stats = st.columns([2, 1])

                        with col_img:
                            st.image(result['image'], caption=result['name'], use_container_width=True)

                        with col_stats:
                            st.write(f"**DÃ©tections:** {result['stats']['total_detections']}")
                            st.write(f"**Temps:** {result['stats']['processing_time']:.2f}s")
                            if result['stats']['total_detections'] > 0:
                                st.write(f"**Confiance moy.:** {result['stats']['average_confidence']:.2f}")

                progress_bar.empty()
                status_text.empty()

    with tab3:
        st.header("ğŸ“¹ DÃ©tection en temps rÃ©el")
        st.info("ğŸš§ FonctionnalitÃ© en dÃ©veloppement - Utilisez la webcam pour la dÃ©tection en temps rÃ©el")

        st.markdown("""
        ### ğŸ¥ Webcam (BientÃ´t disponible)
        Cette fonctionnalitÃ© permettra de:
        - ğŸ“¹ Capturer le flux vidÃ©o de votre webcam
        - ğŸ”„ Analyser les images en temps rÃ©el
        - ğŸ“Š Afficher les statistiques live
        - ğŸ’¾ Enregistrer les dÃ©tections
        """)

        st.subheader("ğŸ¬ Simulation avec images de test")

        if st.button("â–¶ï¸ Lancer la simulation"):
            st.info("Simulation d'un flux vidÃ©o avec des images de test...")
            placeholder = st.empty()
            for i in range(5):
                with placeholder.container():
                    st.write(f"Frame {i + 1}/5")
                    st.progress((i + 1) / 5)
                    time.sleep(1)
            st.success("Simulation terminÃ©e!")

    with tab4:
        st.header("ğŸ“Š Statistiques et monitoring")

        st.subheader("ğŸ§  Informations du modÃ¨le")
        col1, col2 = st.columns(2)

        with col1:
            st.info(f"""
            **ModÃ¨le:** Faster R-CNN ResNet50  
            **Device:** {device}  
            **Seuil de confiance:** {confidence_threshold}  
            **Classes:** PiÃ©ton, ArriÃ¨re-plan  
            """)

        with col2:
            st.info(f"""
            **Fichier modÃ¨le:** {model_path}  
            **Existe:** {'âœ… Oui' if os.path.exists(model_path) else 'âŒ Non'}  
            **Taille max image:** 1024px  
            **Format d'entrÃ©e:** RGB  
            """)

        st.subheader("ğŸ’¡ Conseils d'optimisation")
        st.markdown("""
        ### ğŸ¯ RÃ©glage du seuil de confiance
        - **0.3-0.5:** Plus de dÃ©tections, plus de faux positifs
        - **0.5-0.7:** Ã‰quilibre dÃ©tections/prÃ©cision
        - **0.7-0.9:** Moins de dÃ©tections, plus prÃ©cises

        ### ğŸ–¼ï¸ Optimisation des images
        - **RÃ©solution:** 800-1200px pour un bon Ã©quilibre vitesse/qualitÃ©
        - **Format:** JPG pour des images plus lÃ©gÃ¨res
        - **Ã‰clairage:** Images bien Ã©clairÃ©es donnent de meilleurs rÃ©sultats

        ### âš¡ Performance
        - **GPU:** RecommandÃ© pour le traitement en lot
        - **Batch size:** Traiter par groupes de 10-20 images
        - **MÃ©moire:** Surveiller l'usage mÃ©moire pour de gros lots
        """)

    st.markdown("---")
    st.markdown(
        "ğŸš¶â€â™‚ï¸ **DÃ©tecteur de PiÃ©tons IA** | "
        "PropulsÃ© par PyTorch et Streamlit | "
        "ModÃ¨le: Faster R-CNN ResNet50"
    )


if __name__ == "__main__":
    main()
